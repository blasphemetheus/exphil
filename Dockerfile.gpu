# ExPhil GPU Training Dockerfile
# Multi-stage build for cloud GPU training (RunPod, Lambda Labs, etc.)
#
# Supports: RTX 4090 (Ada Lovelace), RTX 5090 (Blackwell), and other CUDA 12+ GPUs
# CUDA 12.6+ required for Blackwell architecture (Compute Capability 12.0)

# =============================================================================
# Stage 1: Build environment
# =============================================================================
FROM nvidia/cuda:12.6.3-devel-ubuntu22.04 AS builder

ENV DEBIAN_FRONTEND=noninteractive
ENV LANG=C.UTF-8

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    # Build essentials
    build-essential \
    gcc \
    g++ \
    make \
    autoconf \
    libtool \
    git \
    curl \
    ca-certificates \
    unzip \
    # Math libraries for EXLA
    libblas-dev \
    liblapack-dev \
    libopenblas-dev \
    # Python
    python3.11 \
    python3.11-dev \
    python3.11-venv \
    python3-pip \
    # Erlang build deps (for asdf)
    libncurses5-dev \
    libssl-dev \
    libwxgtk3.0-gtk3-dev \
    libwxgtk-webview3.0-gtk3-dev \
    libsctp-dev \
    libodbc1 \
    && rm -rf /var/lib/apt/lists/*

# Install Rust (for Peppi NIF)
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
ENV PATH="/root/.cargo/bin:${PATH}"

# Install asdf version manager
ENV ASDF_DIR="/root/.asdf"
RUN git clone https://github.com/asdf-vm/asdf.git $ASDF_DIR --branch v0.14.0
ENV PATH="${ASDF_DIR}/bin:${ASDF_DIR}/shims:${PATH}"

# Install Erlang and Elixir via asdf
RUN asdf plugin add erlang && asdf plugin add elixir
RUN asdf install erlang 27.0 && asdf global erlang 27.0
RUN asdf install elixir 1.18.1-otp-27 && asdf global elixir 1.18.1-otp-27

# Set up Python
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1 \
    && python3 -m pip install --upgrade pip

WORKDIR /app

# Copy dependency files first (for layer caching)
COPY mix.exs mix.lock ./
COPY config ./config
COPY native ./native
COPY priv/python/requirements.txt ./priv/python/

# Install Elixir dependencies
ENV MIX_ENV=prod
ENV HEX_HTTP_CONCURRENCY=1
ENV HEX_HTTP_TIMEOUT=120

# Set EXLA to compile for CUDA 12 during build
ENV XLA_TARGET=cuda12
ENV EXLA_TARGET=cuda

RUN mix local.hex --force && mix local.rebar --force
RUN mix deps.get --only prod || mix deps.get --only prod

# Install Python dependencies
RUN python3 -m pip install --no-cache-dir -r priv/python/requirements.txt

# Compile Rust NIF and Elixir dependencies (EXLA will download CUDA-enabled XLA)
RUN mix deps.compile

# Copy application code
COPY lib ./lib
COPY scripts ./scripts
COPY priv ./priv
COPY test ./test

# Compile application
RUN mix compile

# =============================================================================
# Stage 2: Runtime environment
# =============================================================================
# Use devel image (not runtime) to include ptxas/nvlink for JIT compilation
# Required for newer GPUs like RTX 5090 (Blackwell) where XLA needs runtime PTX compilation
FROM nvidia/cuda:12.6.3-devel-ubuntu22.04 AS runtime

ENV DEBIAN_FRONTEND=noninteractive
ENV LANG=C.UTF-8
ENV MIX_ENV=prod

# Install runtime dependencies
# Note: NCCL is included in devel images, but cuDNN must be installed separately
RUN apt-get update && apt-get install -y --no-install-recommends \
    # Runtime libs
    libncurses6 \
    libssl3 \
    libstdc++6 \
    libsctp1 \
    # Math libs
    libopenblas0 \
    liblapack3 \
    # Python runtime
    python3.11 \
    python3-pip \
    # Git needed for mix deps with git SCM
    git \
    # Utilities for file transfer and interactive sessions
    curl \
    unzip \
    tmux \
    # cuDNN 9 for deep learning (required by EXLA)
    libcudnn9-cuda-12 \
    && rm -rf /var/lib/apt/lists/* \
    # Install rclone for cloud storage sync
    && curl -s https://rclone.org/install.sh | bash

# Set up Python
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1

# Copy asdf and installed versions from builder
ENV ASDF_DIR="/root/.asdf"
COPY --from=builder /root/.asdf /root/.asdf
ENV PATH="${ASDF_DIR}/bin:${ASDF_DIR}/shims:${PATH}"

# Set asdf versions for runtime
RUN asdf global erlang 27.0 && asdf global elixir 1.18.1-otp-27

# Note: Rust not needed in runtime - Rustler configured with skip_compilation?: true for prod

# Copy Python packages from builder
COPY --from=builder /usr/local/lib/python3.11/dist-packages /usr/local/lib/python3.11/dist-packages

WORKDIR /app

# Copy compiled application from builder
COPY --from=builder /app/_build /app/_build
COPY --from=builder /app/deps /app/deps
COPY --from=builder /app/config /app/config
COPY --from=builder /app/lib /app/lib
COPY --from=builder /app/scripts /app/scripts
COPY --from=builder /app/priv /app/priv
COPY --from=builder /app/test /app/test
COPY --from=builder /app/mix.exs /app/mix.lock /app/

# Set up mix
RUN mix local.hex --force && mix local.rebar --force

# Create directories for data
RUN mkdir -p /app/replays /app/checkpoints /workspace/replays /workspace/checkpoints

# Copy tmux config for better training session experience
COPY config/tmux.conf /root/.tmux.conf

# Make scripts executable
RUN chmod +x /app/scripts/fetch_replays.sh /app/scripts/runpod_entrypoint.sh

# Environment variables for EXLA/CUDA 12
ENV XLA_TARGET=cuda12
ENV EXLA_TARGET=cuda
ENV CUDA_VISIBLE_DEVICES=0

# JAX compilation cache - avoids recompilation across runs
# Cache stored in /workspace so it persists on RunPod volumes
ENV JAX_COMPILATION_CACHE_DIR=/workspace/jax_cache
RUN mkdir -p /workspace/jax_cache

# Entrypoint handles rclone config from env vars
ENTRYPOINT ["/app/scripts/runpod_entrypoint.sh"]

# Keep container running for interactive use
CMD ["sleep", "infinity"]
